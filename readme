pip install Scrapy
next_page = response.css
how to control the recursive depth
how to download specific file, like *.torrent
how to parse specific string, like magnet.*

docs/topics/commands.rst:487 * ``--depth`` or ``-d``: depth level for which the requests should be followed

docs/topics/settings.rst:381 DEPTH_LIMIT
docs/topics/settings.rst:388 The maximum depth that will be allowed to crawl for any site. If zero, no limit
docs/topics/settings.rst:1263 .. setting:: ROBOTSTXT_OBEY
torrent
download
magnet

sehuatang/tutorial/spiders/quotes_spider.py

search page:
scrapy shell 'https://rewrfsrewr.xyz/search.php?mod=forum&searchid=176203&orderby=lastpost&ascdesc=desc&searchsubmit=yes&kw=%E6%97%AC%E6%9E%9C'
response.css('a[href*="forum.php?mod=viewthread"]::attr(href)').getall()

docs/topics/spiders.rst:234             for href in response.xpath('//a/@href').getall():
docs/topics/spiders.rst:464             return response.follow(url, self.parse_additional_page, cb_kwargs=dict(item=item))

next page:
scrapy shell 'https://rewrfsrewr.xyz/search.php?mod=forum&searchid=176203&orderby=lastpost&ascdesc=desc&searchsubmit=yes&kw=%E6%97%AC%E6%9E%9C'
response.xpath("//a[contains(text(), '下一页')]/@href").getall()

sehuatang/tutorial/spiders/quotes_spider.py:21         next_page = response.css('li.next a::attr(href)').get()
quotesbot/quotesbot/spiders/toscrape-css.py:19         next_page_url = response.css("li.next > a::attr(href)").extract_first()

torrent:
scrapy shell 'https://rewrfsrewr.xyz/forum.php?mod=viewthread&tid=83750&highlight=%E5%9B%AD%E7%94%B0'
response.xpath('//*[contains(., ".torrent")]/@href').getall()
response.xpath('//*[contains(., ".torrent")]/@href').get()
https://rewrfsrewr.xyz/forum.php?mod=attachment&aid=NzcxNDd8MzhlYzZmZDd8MTY0MzE3ODUzNXwwfDgzNzUw

from urllib.parse import urlparse

def get_domain(self, response):
    parsed_uri = urlparse(response.url)
    domain = '{uri.scheme}://{uri.netloc}/'.format(uri=parsed_uri)
    print(domain)
    return domain

print(domain + response.xpath('//*[contains(., ".torrent")]/@href').get())

scrapy-examples/sis/sis/spiders/sis_spider.py:52             item['torrents'] = [urljoin(response.url, x) for x in site.css('.t_attachlist a[href*=attachment]::attr(href)').extract()]

download
docs/topics/media-pipeline.rst:527                  yield scrapy.Request(file_url)
docs/topics/media-pipeline.rst:96     ITEM_PIPELINES = {'scrapy.pipelines.files.FilesPipeline': 1}
docs/topics/media-pipeline.rst:108    FILES_STORE = '/path/to/valid/dir'
sehuatang/tutorial/settings.py:65 #ITEM_PIPELINES = {

scrapy/pipelines/media.py:87         requests = arg_to_iter(self.get_media_requests(item, info))
docs/topics/media-pipeline.rst:501         class MyFilesPipeline(FilesPipeline):

magnet:
scrapy shell 'https://rewrfsrewr.xyz/forum.php?mod=viewthread&tid=413893&highlight=%E6%97%AC%E6%9E%9C'
scrapy shell 'https://rewrfsrewr.xyz/forum.php?mod=viewthread&tid=228022&page=1&authorid=328820'
scrapy shell 'https://rewrfsrewr.xyz/forum.php?mod=viewthread&tid=124609&highlight=jenna%20haze'
scrapy shell 'https://rewrfsrewr.xyz/forum.php?mod=viewthread&action=printable&tid=96790'
response.xpath("//*[contains(.,'magnet')]/text()").re(r'(magnet:.*)&dn=.*')


csv

title:
scrapy shell 'https://rewrfsrewr.xyz/forum.php?mod=viewthread&tid=413893&highlight=%E6%97%AC%E6%9E%9C'
response.xpath("//span[@id='thread_subject']/text()").get()

forum:
scrapy shell 'https://rewrfsrewr.xyz/forum-2-1.html'
response.css('a[href*="thread-"][onclick="atarget(this)"]::attr(href)').getall()

scrapy shell 'https://rewrfsrewr.xyz/forum.php?mod=viewthread&tid=124609&highlight=Jenna%20Haze'
scrapy shell 'https://rewrfsrewr.xyz/forum.php?mod=viewthread&tid=612513&highlight=%E4%B8%89%E4%B8%8A%E6%82%A0%E4%BA%9A'

actress:
scrapy shell 'https://rewrfsrewr.xyz/thread-693351-1-1.html'
response.xpath("//*[contains(.,'出演女优')]/text()").re(r'出演女优.*：(.*)')

item

115
scrapy shell 'https://sehuatang.org/forum.php?mod=viewthread&tid=894020&highlight='
response.xpath("//*[contains(.,'115://')]/text()").re(r'115://.*') 

rar
scrapy shell 'https://sehuatang.org/forum.php?mod=viewthread&tid=857296&highlight='
response.xpath('//*[contains(., ".rar")]/@href').getall()
response.xpath('//*[contains(., ".rar")]/text()').re(r'.*.rar')
wget --content-disposition -nc 'https://iming.fj5i3.com/tupian/down_v2.php?sign=eyJ2YWx1ZSI6IkZmcllIaTN5ZG90cFBteTE1Yk5pZVU1eFJCVFAyKzQ2d0QxUmNsWjMwTzNON0h3S0Nia0Q3Y0pxaSttWndhK1NIWjdhdlMxa2RkeTkrUklRbE5aY UlldDFUYzlPeUhxUlhTOVVRRjBFOEFJOHNsNVZzK2dzU2FYMVwvUFZ0ZEFwdmZqM3dWNndZS3BkRmFzOTlzcTBRTUk0MEgrNTlMc3YzNkQzckJaVHc1SHlLTEVHNnRsdDA2VmU5Uk9IOSs3MUNTTHVPVEZ5eVRpSzdwejE1M21HSmpt eWQ0eGVhK0l1VzZKMTRrMDkzSHE3MGZSUE51VGVFZkhPMFwvdGNQMGdvSCIsIml2IjoiOGhTa2VQTjdqWkQwOVZ1VyJ9'

zip
scrapy shell 'https://sehuatang.org/forum.php?mod=viewthread&tid=975008&highlight='
response.xpath('//*[contains(., ".zip")]/@href').getall()
response.xpath('//*[contains(., ".zip")]/text()').re(r'.*.zip')

scrapy shell 'https://sehuatang.org/forum.php?mod=viewthread&tid=975561&highlight='
response.xpath("//*[contains(text(),'magnet')]/text()")
>>> response.xpath("//*[contains(text(),'magnet')]/text()")
[<Selector xpath="//*[contains(text(),'magnet')]/text()" data='magnet:?xt=urn:btih:078EE54CC6F8535E3...'>, <Selector xpath="//*[contains(text(),'magnet')]/text()" data='magnet
:?xt=urn:btih:217A7C7CD8CEE5135...'>]

